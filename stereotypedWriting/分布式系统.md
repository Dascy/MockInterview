## 《深入理解分布式系统》读书笔记

### 1.初识分布式系统

#### 1.1什么是分布式系统

> 分布式系统是一个组件分布在不同的、联网的计算机上，组件之间通过传递消息进行通信和协调。共同完成一个任务的系统

**特点**

1. 多进程，分布式系统有多个进程并发运行
2. 不共享操作系统，通过网络通信进行消息传递
3. 不共享时钟，即不可以简单通过时间来判断事件的执行顺序。

#### 1.2为什么需要分布式系统

分布式系统主要是为了解决（与单机系统比较）：

1. 高性能问题，硬件瓶颈，只能靠堆硬件来提升性能。
2. 可扩展性问题，目前很多系统都是数据密集型。随着业务与数据的增长，单台计算机扩展有限。
3. 高可用性，互联网时代对在线服务要求7*24小时在线，必然会带来高可用的需求。
4. 必要性  跨行转账等必然需求。

#### 1.3分布式系统带来的挑战与问题

1. 网络延迟问题
2. 部分失效问题（部分服务宕机）
3. 时钟问题

### 2.分布式系统模型

#### 2.1两将军问题



#### 2.2拜占庭将军问题



#### 2.3什么是幂等性

幂等性操作是指多次操作产生相同的结果，并且不会有其他影响。

### 3.分布式数据基础

#### 3.1分区

##### 3.1.1分区的概念

分区是分布式系统实现可拓展性的主要方式之一，分为垂直分区和水平分区两种。

##### 3.1.2水平分区算法

###### 3.1.2.1范围分区

范围分区是指根据指定的关键字将数据集拆分为若干连续的范围，每个范围存储到一个单独的节点上。

**优点**

- 实现简单
- 能够对用来分区的关键字进行范围检索
- 当使用的分区键进行范围查询的范围小且位于同一个节点时，性能良好
- 很容易通过修改范围边界增加或者减少范围数据。以平衡负载

**缺点**

- 无法使用分区键之外的其他关键字进行范围查询
- 当查询的范围较大且位于多节点时，性能较差
- 可能产生数据分布不均或请求流量不均的问题。

###### 3.1.2.2哈希分区

将指定关键字经过哈希函数计算，根据hash值来进行分区

**优点**

数据分布几乎随机，相对均匀，能一定程度避免热点问题。

**缺点**

- 在不额外存储数据的情况下，无法进行范围查询
- 添加或者删除节点时，会导致需要重新映射。

###### 3.1.2.3一致性哈希

一致性哈希算法将整个哈希值组织成一个抽象的圆环，称为哈希环，输出值为0到INT_MAX。分布式系统的节点会映射到环上，通过计算哈希值，判断顺时针方向上距离最近的节点。进行存储。

**优点**

很好的解决了哈希分区删除或添加数据导致的大量映射问题。

**缺点**

- 系统节点太少的情况下，还是容易产生数据分布不均问题。
- 当节点异常下线时，容易产生数据倾斜问题。

##### 3.2分区带来的问题

1. 垂直分区的数据集不同表的数据组合查询效率低。
2. 分布式事务问题

#### 3.2复制

除了分区之外，复制同样是提高可用性的有效方式。复制是指将同一份数据冗余存储在多节点上，节点通过网络来同步数据，达到数据一致。

**优点**

1. 增加数据的可用性和安全性
2. 减少数据的往返时间。这里的往返时间是指客户端到服务端的网络传输时间。通过复制技术将数据存储到不同地区的数据中心来减少全国或者全球用户的请求往返时间。
3. 增加吞吐量

**常见的复制类型**

1. 单主复制
2. 多主复制
3. 无主复制

##### 3.2.1单主复制

单主复制也叫主从复制或者主从同步

### CAP&BASE理论

#### CAP理论

##### 简介

**CAP** 也就是 **Consistency（一致性）**、**Availability（可用性）**、**Partition Tolerance（分区容错性）** 这三个单词首字母组合。

![CAP](./picture/ Distributed/cap.png)

- 一致性（Consistency） : 所有节点访问同一份最新的数据副本
- 可用性（Availability）: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。
- 分区容错性（Partition Tolerance） : 分布式系统出现网络分区的时候，仍然能够对外提供服务。

**什么是网络分区**

分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 网络分区。

```
当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。
简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。
```

因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。 比如 ZooKeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。

**选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。**

##### CAP实际用例

注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。

![](./picture/ Distributed/dubbo-architecture.png)

常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos...。

1. **ZooKeeper 保证的是 CP。** 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。
2. **Eureka 保证的则是 AP。** Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。
3. **Nacos 不仅支持 CP 也支持 AP。**

#### BASE理论

##### 简介

BASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求.

**BASE的核心思想**

即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

**BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。**

###### 基本可用

基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。

**什么叫允许损失部分可用性呢？**

- **响应时间上的损失**: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。
- **系统功能上的损失**：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。

###### [#](https://javaguide.cn/distributed-system/theorem&algorithm&protocol/cap&base-theorem.html#%E8%BD%AF%E7%8A%B6%E6%80%81)软状态

软状态指允许系统中的数据存在中间状态（**CAP 理论中的数据不一致**），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

###### [#](https://javaguide.cn/distributed-system/theorem&algorithm&protocol/cap&base-theorem.html#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7)最终一致性

最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

**总结**

**ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。**

### 分布式ID

#### 简介

互联网应用中，某个表可能要占用很大的物理存储空间，为了解决该问题，使用数据库分片技术。将一个数据库进行拆分，通过数据库中间件连接。如果数据库中该表选用ID自增策略，则可能产生重复的ID，此时应该使用分布式ID生成策略来生成ID。

#### 分布式ID常用解决方案

- UUID 这种方案复杂度最低，但是会影响存储空间和性能
- 数据库的自增主键
- redis,zookeeper的特性来生成id  reids 自增命令`incr` `incrby`/zk顺序节点
- 雪花算法  使用64位比特位的long型数据作为唯一ID  首位0固定，表示正数，之后存储41位毫秒级的时间戳。10位存储机器id和服务id 最后12位存储同一时间戳下的自增序列
- 百度-UidGenerator
- 美团leaf

### 分布式锁

#### 什么是分布式锁

分布式系统下，不同的服务/客户端通常运行在独立的 JVM 进程上。如果多个 JVM 进程共享同一份资源的话，使用本地锁就没办法实现资源的互斥访问了。于是，**分布式锁** 就诞生了。

举个例子：系统的订单服务一共部署了 3 份，都对外提供服务。用户下订单之前需要检查库存，为了防止超卖，这里需要加锁以实现对检查库存操作的同步访问。由于订单服务位于不同的 JVM 进程中，本地锁在这种情况下就没办法正常工作了。我们需要用到分布式锁，这样的话，即使多个线程不在同一个 JVM 进程中也能获取到同一把锁，进而实现共享资源的互斥访问。

一个最基本的分布式锁需要满足：

- **互斥** ：任意一个时刻，锁只能被一个线程持有；
- **高可用** ：锁服务是高可用的。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。

通常情况下，我们一般会选择基于 Redis 或者 ZooKeeper 实现分布式锁，Redis 用的要更多一点。

#### 基于Redis实现的分布式锁

------

##### 如何基于Redis实现一个简单分布式锁

不论是实现锁还是分布式锁，核心都在于“互斥”。

在 Redis 中， `SETNX` 命令是可以帮助我们实现互斥。`SETNX` 即 **SET** if **N**ot eXists (对应 Java 中的 `setIfAbsent` 方法)，如果 key 不存在的话，才会设置 key 的值。如果 key 已经存在， `SETNX` 啥也不做。

```shell
> SETNX lockKey uniqueValue
(integer) 1
> SETNX lockKey uniqueValue
(integer) 0
```

释放锁的话，直接通过 `DEL` 命令删除对应的 key 即可。

```shell
> DEL lockKey
(integer) 1
```

为了误删到其他的锁，这里我们建议使用 Lua 脚本通过 key 对应的 value（唯一值）来判断。

选用 Lua 脚本是为了保证解锁操作的原子性。因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性。

```shell
// 释放锁时，先比较锁对应的 value 值是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end

```

这是一种最简易的 Redis 分布式锁实现，实现方式比较简单，性能也很高效。不过，这种方式实现分布式锁存在一些问题。就比如应用程序遇到一些问题比如释放锁的逻辑突然挂掉，可能会导致锁无法被释放，进而造成共享资源无法再被其他线程/进程访问。

##### 给锁加一个过期时间

为了避免锁无法被释放，我们可以想到的一个解决办法就是：给这个 key（也就是锁） 设置一个过期时间。

```shell
SET lockKey uniqueValue EX 3 NX
```

- **lockKey** ：加锁的锁名；
- **uniqueValue** ：能够唯一标示锁的随机字符串；
- **NX** ：只有当 lockKey 对应的 key 值不存在的时候才能 SET 成功；
- **EX** ：过期时间设置（秒为单位）EX 3 标示这个锁有一个 3 秒的自动过期时间。与 EX 对应的是 PX（毫秒为单位），这两个都是过期时间设置。

这样确实可以解决问题，不过，这种解决办法同样存在漏洞：**如果操作共享资源的时间大于过期时间，就会出现锁提前过期的问题，进而导致分布式锁直接失效。如果锁的超时时间设置过长，又会影响到性能**

##### 如何续期

对于 Java 开发的小伙伴来说，已经有了现成的解决方案：**Redissonopen in new window** 。其他语言的解决方案，可以在 Redis 官方文档中找到，地址：https://redis.io/topics/distlock 。

Redisson 是一个开源的 Java 语言 Redis 客户端，提供了很多开箱即用的功能，不仅仅包括多种分布式锁的实现。并且，Redisson 还支持 Redis 单机、Redis Sentinel 、Redis Cluster 等多种部署架构。

Redisson 中的分布式锁自带自动续期机制，使用起来非常简单，原理也比较简单，其提供了一个专门用来监控和续期锁的 **Watch Dog（ 看门狗）**，如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。

### 分布式事务

#### 什是分布式事务

> **事务**是一个程序执行单元，里面的所有操作要么全部执行成功，要么全部执行失败。在分布式系统中，这些操作可能是位于不同的服务中，那么如果也能保证这些操作要么全部执行成功要么全部执行失败呢？这便是分布式事务要解决的问题。

**经典场景下订单**

单体应用下所有业务使用同一个数据库，下单流程只在同一个数据库中操作同一个事务。事务要么全部回归，要么全提交成功。

![image](https://raw.githubusercontent.com/Dascy/Image/9cfc2841e603f2cc5f78ee2028dc47fb377931d6/blog/2024/03/06/01f8b3eabf06e4db6814aa4d0a5a9f72-arch-z-transection-2-52f357.png)

随着业务的增长，业务服务不断分化。上面的服务分离成订单中心、库存中心等。这样就造成了业务相互隔离。每个业务都维护者自己的数据库，数据交换通过服务调用来进行。

用户再次下单时，就要保证对订单中心和库存中心的操作要同步进行且成功。一旦失败发生，可能造成数据的不一致。这个时候遇到的问题就要介入分布式事务来进行解决。

![img](https://raw.githubusercontent.com/Dascy/Image/master/blog/2024/03/06/73024c491fb704ee6ee9b2ef9c80fe70-arch-z-transection-3-3b075e.png)

#### 分布式事务体系

![](https://raw.githubusercontent.com/Dascy/Image/master/distributed%20system/system.png)

#### **刚性事务**

分布式理论的CP，遵循ACID，对数据要求强一致性。

 **XA协议** 是一个基于数据库层面的分布式事务协议，其分为两部分：**事务管理器**  和  **本地资源管理器** 事务管理器作为一个全局的调度者，负责所有的本地资源管理器统一号令提交或者回滚。

**JTA/JTS** 是Java事务API(Java Transaction API) 和Java事务服务（Java Transaction Service）

##### 二段提交协议（2PC）     

两段提交（2PC - Prepare&Commit） 是指两个阶段的提交方式：

- 第一阶段：准备阶段

​        1.协调者向所有参与者发送准备消息，询问参与者是否可以提交事务。等待参与者响应。

​        2.参与者接收到消息后，检查执行事务所需条件和资源，准备好后执行事务操作并且记录日志。

​        3.参与者响应协调者的请求。如果参与者执行事务的操作成功，返回是，失败或者超时，返回否。

- 第二阶段：提交阶段

​        1.协调者接收到响应后，如果所有的回复为是，则发送提交事务的消息。否则，回复回滚命令。并等待参与者响应。

​        2.参与者接收协调者的请求后，依据命令提交或者回滚事务。并向协调者发送消息确认。

**缺点**

- **网络抖动导致的数据不一致问题** 第二阶段协调者发送提交命令时，发生网络抖动。一部分参与者接收到请求并执行。另一部分未接收到命令。导致数据不一致。
- **超时导致的同步阻塞问题** 所有参与者都为事务阻塞型，当一个参与者超时，其他参与者都被动的阻塞占用资源。
- **单点故障的风险 ** 协调者依赖严重，一旦协调者发生故障，参与者处于锁定资源的状态，无法完成事务的提交。

##### 三段提交协议（3PC）

3PC是在2PC的基础上提交了pre-Commit 预提交的阶段。

- 第一阶段：准备阶段 (CanCommit)

​       协调者向参与者发送准备提交消息。询问是否可以执行事务提交操作。如果全部响应，进入下一个阶段。

- 第二阶段：预提交阶段(PreCommit)

​       协调者向所有参与者发送预提交消息。询问是否可以进行事务的预提交操作。参与者接收到请求后，如果参与者执行了事务操作，返回Yes，进入提交阶段。一旦存在参与者返回No响应或者网络造成超时，协调者没能接收到参与者响应，协调者向参与者发送中断请求。参与者中断事务。

- 第三阶段：提交阶段(DoCommit)

​       所有参与者响应为yes，协调者向参与者发送提交请求。如果协调者没有收到参与者的响应，会向参与者发送回滚命令。

**缺点**

3PC是非阻塞性协议。参与者会在协调者故障时选出新的协调者。增加了可用性。防止了单点故障。

3PC容易受到网络分区的影响。例如在预提交阶段发生网络分区。将参与者中接收到消息和未接收到的一分为二，同时协调者故障。导致两边各选举出来一个协调者。最终导致数据的不一致。

3PC 需要至少三轮消息往返。增加了事务的完成时间。

**小结**

3PC没有完美解决2PC的阻塞，也引入 了新的问题。通常我们在设计分布式事务的时候通过共识性算法例如Paxos算法实现2PC的第一阶段。

### 柔性事务

分布式理论的AP，遵循BASE，允许一定时间内不同节点的数据不一致，但要求最终一致。

#### 补偿事务（TCC）

TCC（Try-Confirm-Cancel） 又称补偿事务。TCC跟2PC的思想相似。不过是应用层面的。需要通过业务代码来实现。

核心思想是针对每一个操作都要注册一个与其对应的确认和补偿。

- Try阶段。 通过Try操作来扣除预留资源。
- Confirm阶段。确认执行业务操作，在预留的资源接触上来执行。
- Cancel阶段。有一个业务方预留资源未能成功，则取消所有业务的资源预留请求。

**缺点**

1.空回滚

一个分支事务发生宕机，未能执行try方法。回复后执行cancel方法，无法处理此情况就会出现空回滚。

通常通过创建分支事务表来进行记录。来判断是否发生空回滚。

2.幂等性问题

由于服务宕机或者网络问题，方法调用超时，为了保证事务的正常执行。我们通常会加入重试机制。因此就需要保证confirm和cancel阶段操作的幂等性。

3.悬挂问题

TCC中，在try调用前会先注册分支事务。分支事务注册完成后，调用出现超时。此时try还未到达服务端。因为超时，所以执行了cancel。cancel执行结束后，try请求到达。这个时候执行了try就没有后续了，导致资源挂起。无法释放。

#### Saga事务

Saga是由一些列本地事务构成，每一个本地事务完成后，会通过消息或者事件触发下一个事务的执行。当一个本地事务失败时，Saga会执行在这个事务失败之前成功提交的所有事务的补偿操作。有两种实现方式：

- 基于事件方式

​       整体逻辑是根据业务逻辑，后者监听前一个业务的完成情况。来出发自己的任务执行。

​      **优点**

​       简单，容易理解。完全解耦合

​      **缺点**

​       容易失控，形成环形依赖。

- 基于命令方式

​       维护一个协调中心，通过协调中心发送命令给不同的业务方。当某一方失败时，协调中心出发回滚流程。

​       **优点**

​       1.避免业务方之间形成环形依赖

​       2.将分布式事务的管理交给协调中心管理，协调中心对整个逻辑非常清楚

​       3.减少了业务参与方的复杂组。

​       4.容易测试 

​       5.容易回滚。

​      **缺点**

​       需要维护一个额外的协调中心。         

### 基于最终一致性

#### 本地消息表

​    整体流程如下

![img](https://raw.githubusercontent.com/Dascy/Image/master/blog/2024/03/06/517a50fb29e15abf610a9160667c62ee-arch-transection-41-216d62.png)

#### MQ事务方案（可靠消息事务）

对本地消息表的优化。将消息表维护到了MQ中

#### 最大努力通知

对MQ事务方式对优化。追加了消息校验接口。

### 分布式事务中间件Seata

